# MAViS: An Audio-visual Conversational Assistant For Avian Species

[![Paper](https://img.shields.io/badge/Paper-EMNLP%202025-blue)](https://openreview.net/forum?id=AsPeZSZl5c)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

This repository will host the official implementation, dataset splits, and pretrained models from our paper:

**"MAviS: An Audio-visual Conversational Assistant For Avian Species"**  
*(EMNLP 2025, Oral Presentation, Top 15% of Submissions)*

---

## ðŸš€ Overview
MAViS introduces the first large-scale multimodal framework for fine-grained avian species identification.  
It consists of three main pillars:
- **MAViS-Dataset**: Over 1,000 bird species with curated images, audio, and text.  
- **MAViS-Bench**: A benchmark of multimodal QA pairs for evaluating reasoning across modalities.  
- **MAViS-CPM**: A domain-adapted multimodal LLM fine-tuned for species recognition and reasoning.  

---

---

## ðŸ”œ Coming Soon
- [ ] Preprocessing scripts for dataset curation  
- [ ] Training and fine-tuning code for MAViS-CPM  
- [ ] Checkpoints (base, fine-tuned, ablation variants)  
- [ ] Benchmark evaluation toolkit (MAViS-Bench + MAviS-Eval)  

Stay tuned for updates around the **camera-ready release**.  

---

## ðŸ“– Citation
If you find this work useful, please cite our paper:

```bibtex
@inproceedings{kryklyvets2025mavis,
  title={{MA}viS: An Audio-visual Conversational Assistant For Avian Species},
  author={Kryklyvets, Yevheniia and Kurpath, Mohammed Irfan and Mullappilly, Sahal Shaji and Zhou, Jinxing and Khan, Fahad Shahbaz and Anwer, Rao Muhammad and Khan, Salman and Cholakkal, Hisham},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  year={2025},
  url={https://openreview.net/forum?id=AsPeZSZl5c}
}

